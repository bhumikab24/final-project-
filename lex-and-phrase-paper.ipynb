{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11505261,"sourceType":"datasetVersion","datasetId":7213646},{"sourceId":11505493,"sourceType":"datasetVersion","datasetId":7213819},{"sourceId":11505604,"sourceType":"datasetVersion","datasetId":7213894},{"sourceId":11505841,"sourceType":"datasetVersion","datasetId":7214072},{"sourceId":11505900,"sourceType":"datasetVersion","datasetId":7214119},{"sourceId":11524787,"sourceType":"datasetVersion","datasetId":7227797},{"sourceId":11525118,"sourceType":"datasetVersion","datasetId":7228037},{"sourceId":11527373,"sourceType":"datasetVersion","datasetId":7229800}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kannada to English Machine Translation System\n# Based strictly on the methodology from the MT paper (Rule-based, Lexical + Phrase Mapping)\n\nimport json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\n# === 1. Load Dataset ===\nwith open(\"/kaggle/input/datapaper/neww dataset.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\n# === 2. Create Lexical Resources ===\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === 3. Normalize Text ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\n# === 4. Transliteration (Fallback) ===\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === 5. Lexical Translation (Word Level) ===\ndef translate_word(word):\n    if word in words_dict:\n        return words_dict[word]\n    root = normalize_kannada(word)\n    return words_dict.get(root, transliterate_kannada(word))\n\n# === 6. Phrase Dictionary Lookup ===\nphrase_dict = {p[\"kannada\"]: p[\"english\"] for p in phrases if \"id\" in p}\n\ndef translate_using_phrase(sentence):\n    return phrase_dict.get(sentence, None)\n\n# === 7. Grammar-Based Sentence Parsing ===\n# Simulated recursive-descent-like rule matching for simple SOV Kannada sentences\nverb_list = [\"‡≤¨‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü\", \"‡≤π‡≥ã‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤æ‡≤®‡≥Ü\", \"‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤æ‡≤®‡≥Ü\", \"‡≤á‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü\"]  # Extendable\n\ndef parse_simple_sentence(tokens):\n    if len(tokens) == 3 and tokens[2] in verb_list:\n        return {\"type\": \"SOV\", \"subject\": tokens[0], \"object\": tokens[1], \"verb\": tokens[2]}\n    return None\n\n# === 8. Phrase Mapping or Lexical Fallback ===\ndef translate(sentence):\n    phrase_match = translate_using_phrase(sentence)\n    if phrase_match:\n        return phrase_match\n    tokens = sentence.split()\n    parsed = parse_simple_sentence(tokens)\n    if parsed:\n        s = translate_word(parsed[\"subject\"])\n        o = translate_word(parsed[\"object\"])\n        v = translate_word(parsed[\"verb\"])\n        return f\"{s} {o} {v}\"\n    return \" \".join(translate_word(w) for w in tokens)\n\n# === 9. Evaluation Metrics ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref, pred):\n    ref_words = ref.split()\n    pred_words = pred.split()\n    correct = sum(r == p for r, p in zip(ref_words, pred_words))\n    return correct / max(len(ref_words), 1)\n\n# === 10. Evaluate Dataset ===\ntotal_bleu = 0\nsentence_correct = 0\ntotal_word_acc = 0\ntotal_bleu_word_acc = 0\nsample_count = 0\n\nfor p in phrases:\n    if \"kannada\" in p and \"english\" in p:\n        kannada = normalize_text(p[\"kannada\"])\n        expected = normalize_text(p[\"english\"])\n        predicted = normalize_text(translate(kannada))\n\n        if predicted == expected:\n            sentence_correct += 1\n\n        b = bleu(expected, predicted)\n        w = word_level_accuracy(expected, predicted)\n\n        total_bleu += b\n        total_word_acc += w\n        total_bleu_word_acc += b * w\n        sample_count += 1\n\n# === 11. Final Report ===\nprint(\"\\nüìä Final Evaluation Report (Based on MT Paper Methodology)\")\nprint(f\"‚úÖ Sentence-Level Accuracy: {round((sentence_correct / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ Word-Level Accuracy: {round((total_word_acc / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ Average BLEU Score (with smoothing): {round((total_bleu / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ BLEU √ó Word Accuracy Score: {round((total_bleu_word_acc / sample_count) * 100, 2)}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ************ Add Part-of-Speech (POS) Tagging + Tense & Gender**********************","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\n# === 1. Load the updated dataset ===\nwith open(\"/kaggle/input/pos-and-tense/neww_dataset_with_pos_gender_tense.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\n# === 2. Mappings ===\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === 3. Normalization ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\n# === 4. Transliteration Fallback ===\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === 5. Word Translator with POS awareness ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === 6. Phrase Lookup ===\nphrase_dict = {p[\"kannada\"]: p[\"english\"] for p in phrases if \"id\" in p}\ndef translate_using_phrase(sentence):\n    return phrase_dict.get(sentence, None)\n\n# === 7. Grammar Rule: SOV Parsing ===\ndef parse_simple_sentence(tokens):\n    if len(tokens) == 3:\n        subj = translate_word_structured(tokens[0])\n        obj = translate_word_structured(tokens[1])\n        verb = translate_word_structured(tokens[2])\n        if verb.get(\"pos\") == \"verb\":\n            return {\"type\": \"SOV\", \"subject\": subj, \"object\": obj, \"verb\": verb}\n    return None\n\n# === 8. Translate Sentence ===\ndef translate(sentence):\n    phrase_match = translate_using_phrase(sentence)\n    if phrase_match:\n        return phrase_match\n    tokens = sentence.split()\n    parsed = parse_simple_sentence(tokens)\n    if parsed:\n        s = parsed[\"subject\"][\"english\"]\n        o = parsed[\"object\"][\"english\"]\n        v = parsed[\"verb\"][\"english\"]\n        return f\"{s} {o} {v}\"\n    return \" \".join(translate_word_structured(w)[\"english\"] for w in tokens)\n\n# === 9. BLEU & Word Accuracy ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref, pred):\n    ref_words = ref.split()\n    pred_words = pred.split()\n    correct = sum(r == p for r, p in zip(ref_words, pred_words))\n    return correct / max(len(ref_words), 1)\n\n# === 10. Evaluation Loop ===\ntotal_bleu = 0\nsentence_correct = 0\ntotal_word_acc = 0\ntotal_bleu_word_acc = 0\nsample_count = 0\n\nfor p in phrases:\n    if \"kannada\" in p and \"english\" in p:\n        kannada = normalize_text(p[\"kannada\"])\n        expected = normalize_text(p[\"english\"])\n        predicted = normalize_text(translate(kannada))\n\n        if predicted == expected:\n            sentence_correct += 1\n\n        b = bleu(expected, predicted)\n        w = word_level_accuracy(expected, predicted)\n\n        total_bleu += b\n        total_word_acc += w\n        total_bleu_word_acc += b * w\n        sample_count += 1\n\n# === 11. Final Report ===\nprint(\"\\nüìä Final Evaluation Report (With POS, Tense, Gender Support)\")\nprint(f\"‚úÖ Sentence-Level Accuracy: {round((sentence_correct / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ Word-Level Accuracy: {round((total_word_acc / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ Average BLEU Score (with smoothing): {round((total_bleu / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ BLEU √ó Word Accuracy Score: {round((total_bleu_word_acc / sample_count) * 100, 2)}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\n# === 1. Load the combined dataset ===\nwith open(\"/kaggle/input/pos-and-tense1/full_dataset_with_pos_gender_test_phrases.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\n# === 2. Create mapping dictionaries ===\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === 3. Text normalization ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\n# === 4. Transliteration fallback ===\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === 5. Word translator with POS support ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === 6. Phrase mapping ===\nphrase_dict = {p[\"kannada\"]: p[\"english\"] for p in phrases if \"id\" in p}\n\ndef translate_using_phrase(sentence):\n    return phrase_dict.get(sentence, None)\n\n# === 7. Grammar-based SOV parsing ===\ndef parse_simple_sentence(tokens):\n    if len(tokens) == 3:\n        subj = translate_word_structured(tokens[0])\n        obj = translate_word_structured(tokens[1])\n        verb = translate_word_structured(tokens[2])\n        if verb.get(\"pos\") == \"verb\":\n            return {\"type\": \"SOV\", \"subject\": subj, \"object\": obj, \"verb\": verb}\n    return None\n\n# === 8. Sentence-level translation ===\ndef translate(sentence):\n    phrase_match = translate_using_phrase(sentence)\n    if phrase_match:\n        return phrase_match\n    tokens = sentence.split()\n    parsed = parse_simple_sentence(tokens)\n    if parsed:\n        s = parsed[\"subject\"][\"english\"]\n        o = parsed[\"object\"][\"english\"]\n        v = parsed[\"verb\"][\"english\"]\n        return f\"{s} {o} {v}\"\n    return \" \".join(translate_word_structured(w)[\"english\"] for w in tokens)\n\n# === 9. Evaluation functions ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref, pred):\n    ref_words = ref.split()\n    pred_words = pred.split()\n    correct = sum(r == p for r, p in zip(ref_words, pred_words))\n    return correct / max(len(ref_words), 1)\n\n# === 10. Evaluate the dataset ===\ntotal_bleu = 0\nsentence_correct = 0\ntotal_word_acc = 0\ntotal_bleu_word_acc = 0\nsample_count = 0\n\nfor p in phrases:\n    if \"kannada\" in p and \"english\" in p:\n        kannada = normalize_text(p[\"kannada\"])\n        expected = normalize_text(p[\"english\"])\n        predicted = normalize_text(translate(kannada))\n\n        if predicted == expected:\n            sentence_correct += 1\n\n        b = bleu(expected, predicted)\n        w = word_level_accuracy(expected, predicted)\n\n        total_bleu += b\n        total_word_acc += w\n        total_bleu_word_acc += b * w\n        sample_count += 1\n\n# === 11. Final report ===\nprint(\"\\nüìä Final Evaluation Report (Full Dataset with POS, Tense, Gender Support)\")\nprint(f\"‚úÖ Sentence-Level Accuracy: {round((sentence_correct / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ Word-Level Accuracy: {round((total_word_acc / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ Average BLEU Score (with smoothing): {round((total_bleu / sample_count) * 100, 2)}%\")\nprint(f\"‚úÖ BLEU √ó Word Accuracy Score: {round((total_bleu_word_acc / sample_count) * 100, 2)}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# **************************FOR METEOR SCORE *****************************************","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from nltk.translate.meteor_score import meteor_score\nimport json\nimport re\n\n# === Load the updated dataset ===\nwith open(\"/kaggle/input/pos-and-tense1/full_dataset_with_pos_gender_test_phrases.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\n# === Transliteration maps ===\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === Utilities ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === Phrase map ===\nphrase_dict = {p[\"kannada\"]: p[\"english\"] for p in phrases if \"id\" in p}\ndef translate_using_phrase(sentence):\n    return phrase_dict.get(sentence, None)\n\ndef parse_simple_sentence(tokens):\n    if len(tokens) == 3:\n        subj = translate_word_structured(tokens[0])\n        obj = translate_word_structured(tokens[1])\n        verb = translate_word_structured(tokens[2])\n        if verb.get(\"pos\") == \"verb\":\n            return {\"type\": \"SOV\", \"subject\": subj, \"object\": obj, \"verb\": verb}\n    return None\n\n# === Final Translator ===\ndef translate(sentence):\n    phrase_match = translate_using_phrase(sentence)\n    if phrase_match:\n        return phrase_match\n    tokens = sentence.split()\n    parsed = parse_simple_sentence(tokens)\n    if parsed:\n        s = parsed[\"subject\"][\"english\"]\n        o = parsed[\"object\"][\"english\"]\n        v = parsed[\"verb\"][\"english\"]\n        return f\"{s} {o} {v}\"\n    return \" \".join(translate_word_structured(w)[\"english\"] for w in tokens)\n\n# === METEOR Evaluation Loop ===\ntotal_meteor = 0\nsample_count = 0\n\nfor p in phrases:\n    if \"kannada\" in p and \"english\" in p:\n        kannada = normalize_text(p[\"kannada\"])\n        expected = normalize_text(p[\"english\"])\n        predicted = normalize_text(translate(kannada))\n\n        score = meteor_score([expected.split()], predicted.split())\n        total_meteor += score\n        sample_count += 1\n\n\n# === Final METEOR Score ===\naverage_meteor = total_meteor / sample_count\nprint(f\"\\nüìä METEOR Evaluation Score: {round(average_meteor * 100, 2)}%\")\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# **********************(with Enriched Words Dictionary)****************************","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kannada to English Machine Translation System (with Enriched Words Dictionary)\n\nimport json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom nltk.translate.meteor_score import meteor_score\n\n# === Load enriched dataset ===\nwith open(\"/kaggle/input/word-dict/full_dataset_enriched_words.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === Normalization Functions ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\n# === Transliteration Fallback ===\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === Word Translation ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        if isinstance(entry[\"english\"], list):\n            entry[\"english\"] = entry[\"english\"][0]  # default to first synonym\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === Phrase Lookup ===\nphrase_dict = {p[\"kannada\"]: p[\"english\"] for p in phrases if \"id\" in p}\n\ndef translate_using_phrase(sentence):\n    return phrase_dict.get(sentence, None)\n\n# === Simple SOV Grammar Parsing ===\ndef parse_simple_sentence(tokens):\n    if len(tokens) == 3:\n        subj = translate_word_structured(tokens[0])\n        obj = translate_word_structured(tokens[1])\n        verb = translate_word_structured(tokens[2])\n        if verb.get(\"pos\") == \"verb\":\n            return {\"type\": \"SOV\", \"subject\": subj, \"object\": obj, \"verb\": verb}\n    return None\n\n# === Sentence Translation ===\ndef translate(sentence):\n    phrase_match = translate_using_phrase(sentence)\n    if phrase_match:\n        return phrase_match\n    tokens = sentence.split()\n    parsed = parse_simple_sentence(tokens)\n    if parsed:\n        s = parsed[\"subject\"][\"english\"]\n        o = parsed[\"object\"][\"english\"]\n        v = parsed[\"verb\"][\"english\"]\n        return f\"{s} {o} {v}\"\n    return \" \".join(translate_word_structured(w)[\"english\"] for w in tokens)\n\n# === Evaluation Metrics ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref, pred):\n    ref_words = ref.split()\n    pred_words = pred.split()\n    correct = sum(r == p for r, p in zip(ref_words, pred_words))\n    return correct / max(len(ref_words), 1)\n\n# === Evaluate Dataset ===\ntotal_bleu = 0\ntotal_meteor = 0\nsentence_correct = 0\ntotal_word_acc = 0\ntotal_bleu_word_acc = 0\nsample_count = 0\n\nfor p in phrases:\n    if \"kannada\" in p and \"english\" in p:\n        kannada = normalize_text(p[\"kannada\"])\n        expected = normalize_text(p[\"english\"])\n        predicted = normalize_text(translate(kannada))\n\n        if predicted == expected:\n            sentence_correct += 1\n\n        b = bleu(expected, predicted)\n        w = word_level_accuracy(expected, predicted)\n        m = meteor_score([expected.split()], predicted.split())\n\n        total_bleu += b\n        total_meteor += m\n        total_word_acc += w\n        total_bleu_word_acc += b * w\n        sample_count += 1\n\n# === Final Scores ===\navg_sentence_acc = (sentence_correct / sample_count) * 100\navg_word_acc = (total_word_acc / sample_count) * 100\navg_bleu = (total_bleu / sample_count) * 100\navg_meteor = (total_meteor / sample_count) * 100\navg_combined = (avg_sentence_acc + avg_word_acc + avg_bleu + avg_meteor) / 4\n\n# === Final Report ===\nprint(\"\\nüìä Evaluation Report (Enriched Words Version)\")\nprint(f\"‚úÖ Sentence-Level Accuracy: {avg_sentence_acc:.2f}%\")\nprint(f\"‚úÖ Word-Level Accuracy: {avg_word_acc:.2f}%\")\nprint(f\"‚úÖ BLEU Score: {avg_bleu:.2f}%\")\nprint(f\"‚úÖ METEOR Score: {avg_meteor:.2f}%\")\nprint(f\"‚úÖ Average Translation Accuracy: {avg_combined:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:23:41.151472Z","iopub.execute_input":"2025-04-23T10:23:41.151795Z","iopub.status.idle":"2025-04-23T10:23:45.903945Z","shell.execute_reply.started":"2025-04-23T10:23:41.151763Z","shell.execute_reply":"2025-04-23T10:23:45.903137Z"}},"outputs":[{"name":"stdout","text":"\nüìä Evaluation Report (Enriched Words Version)\n‚úÖ Sentence-Level Accuracy: 93.16%\n‚úÖ Word-Level Accuracy: 94.23%\n‚úÖ BLEU Score: 72.00%\n‚úÖ METEOR Score: 94.31%\n‚úÖ Average Translation Accuracy: 88.43%\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ***********************Enriched Word Dictionary + Synonyms****************************","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kannada to English MT Evaluation with Enriched Word Dictionary + Synonyms\n\nimport json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom nltk.translate.meteor_score import meteor_score\n\n# === Load enriched dataset with extended synonyms and verb forms ===\nwith open(\"/kaggle/input/word-dict1/full_dataset_enriched_words_plus_synonyms.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === Normalization ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\n# === Transliteration ===\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === Word Translator ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        if isinstance(entry[\"english\"], list):\n            entry = entry.copy()\n            entry[\"english\"] = entry[\"english\"][0]  # Use first synonym\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === Phrase Mapping ===\nphrase_dict = {p[\"kannada\"]: p[\"english\"] for p in phrases if \"id\" in p}\n\ndef translate_using_phrase(sentence):\n    return phrase_dict.get(sentence, None)\n\n# === Grammar Parsing ===\ndef parse_simple_sentence(tokens):\n    if len(tokens) == 3:\n        subj = translate_word_structured(tokens[0])\n        obj = translate_word_structured(tokens[1])\n        verb = translate_word_structured(tokens[2])\n        if verb.get(\"pos\") == \"verb\":\n            return {\"type\": \"SOV\", \"subject\": subj, \"object\": obj, \"verb\": verb}\n    return None\n\n# === Sentence Translator ===\ndef translate(sentence):\n    phrase_match = translate_using_phrase(sentence)\n    if phrase_match:\n        return phrase_match\n    tokens = sentence.split()\n    parsed = parse_simple_sentence(tokens)\n    if parsed:\n        s = parsed[\"subject\"][\"english\"]\n        o = parsed[\"object\"][\"english\"]\n        v = parsed[\"verb\"][\"english\"]\n        return f\"{s} {o} {v}\"\n    return \" \".join(translate_word_structured(w)[\"english\"] for w in tokens)\n\n# === Evaluation Functions ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref, pred):\n    ref_words = ref.split()\n    pred_words = pred.split()\n    correct = sum(r == p for r, p in zip(ref_words, pred_words))\n    return correct / max(len(ref_words), 1)\n\n# === Evaluation Loop ===\ntotal_bleu = 0\ntotal_meteor = 0\nsentence_correct = 0\ntotal_word_acc = 0\ntotal_bleu_word_acc = 0\nsample_count = 0\n\nfor p in phrases:\n    if \"kannada\" in p and \"english\" in p:\n        kannada = normalize_text(p[\"kannada\"])\n        expected = normalize_text(p[\"english\"])\n        predicted = normalize_text(translate(kannada))\n\n        if predicted == expected:\n            sentence_correct += 1\n\n        b = bleu(expected, predicted)\n        w = word_level_accuracy(expected, predicted)\n        m = meteor_score([expected.split()], predicted.split())\n\n        total_bleu += b\n        total_meteor += m\n        total_word_acc += w\n        total_bleu_word_acc += b * w\n        sample_count += 1\n\n# === Final Accuracy Metrics ===\navg_sentence_acc = (sentence_correct / sample_count) * 100\navg_word_acc = (total_word_acc / sample_count) * 100\navg_bleu = (total_bleu / sample_count) * 100\navg_meteor = (total_meteor / sample_count) * 100\navg_combined = (avg_sentence_acc + avg_word_acc + avg_bleu + avg_meteor) / 4\n\n# === Final Report ===\nprint(\"\\nüìä Evaluation Report (Synonym & Enriched Word Version)\")\nprint(f\"‚úÖ Sentence-Level Accuracy: {avg_sentence_acc:.2f}%\")\nprint(f\"‚úÖ Word-Level Accuracy: {avg_word_acc:.2f}%\")\nprint(f\"‚úÖ BLEU Score: {avg_bleu:.2f}%\")\nprint(f\"‚úÖ METEOR Score: {avg_meteor:.2f}%\")\nprint(f\"‚úÖ Average Translation Accuracy: {avg_combined:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:23:51.832111Z","iopub.execute_input":"2025-04-23T10:23:51.832503Z","iopub.status.idle":"2025-04-23T10:23:51.894853Z","shell.execute_reply.started":"2025-04-23T10:23:51.832480Z","shell.execute_reply":"2025-04-23T10:23:51.894117Z"}},"outputs":[{"name":"stdout","text":"\nüìä Evaluation Report (Synonym & Enriched Word Version)\n‚úÖ Sentence-Level Accuracy: 93.16%\n‚úÖ Word-Level Accuracy: 94.23%\n‚úÖ BLEU Score: 72.00%\n‚úÖ METEOR Score: 94.31%\n‚úÖ Average Translation Accuracy: 88.43%\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(translate(\"‡≤™‡≤†‡≥ç‡≤Ø‡≤™‡≥Å‡≤∏‡≥ç‡≤§‡≤ï\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:24:20.864268Z","iopub.execute_input":"2025-04-23T10:24:20.864582Z","iopub.status.idle":"2025-04-23T10:24:20.869620Z","shell.execute_reply.started":"2025-04-23T10:24:20.864559Z","shell.execute_reply":"2025-04-23T10:24:20.868784Z"}},"outputs":[{"name":"stdout","text":"textbook\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"#*****************************interrogatives****************************************","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kannada to English MT with Interrogative Grammar Fix\n\nimport json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom nltk.translate.meteor_score import meteor_score\n\n# === Load Dataset ===\nwith open(\"/kaggle/input/newtrail/dataset_with_interrogatives.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === Utilities ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\", \"?\", \".\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === Translation Logic ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        if isinstance(entry[\"english\"], list):\n            entry = entry.copy()\n            entry[\"english\"] = entry[\"english\"][0]\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === Question Handling ===\ndef is_question(sentence):\n    return sentence.strip().endswith(\"?\") or any(q in sentence for q in [\"‡≤Ø‡≤æ‡≤∞‡≥Å\", \"‡≤è‡≤®‡≥Å\", \"‡≤é‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤é‡≤≤‡≥ç‡≤≤‡≤ø‡≤ó‡≥Ü\"])\n\nquestion_map = {\n    \"‡≤Ø‡≤æ‡≤∞‡≥Å\": \"who\",\n    \"‡≤è‡≤®‡≥Å\": \"what\",\n    \"‡≤é‡≤≤‡≥ç‡≤≤‡≤ø\": \"where\",\n    \"‡≤é‡≤≤‡≥ç‡≤≤‡≤ø‡≤ó‡≥Ü\": \"where\",\n    \"‡≤é‡≤∑‡≥ç‡≤ü‡≥Å\": \"how much\",\n    \"‡≤Ø‡≤æ‡≤ï‡≥Ü\": \"why\",\n    \"‡≤Ø‡≤æ‡≤µ‡≤æ‡≤ó\": \"when\"\n}\n\n# === Phrase Lookup ===\nphrase_dict = {p[\"kannada\"]: p[\"english\"] for p in phrases if \"id\" in p}\n\ndef translate_using_phrase(sentence):\n    return phrase_dict.get(sentence, None)\n\ndef parse_simple_sentence(tokens):\n    if len(tokens) == 3:\n        subj = translate_word_structured(tokens[0])\n        obj = translate_word_structured(tokens[1])\n        verb = translate_word_structured(tokens[2])\n        if verb.get(\"pos\") == \"verb\":\n            return {\"type\": \"SOV\", \"subject\": subj, \"object\": obj, \"verb\": verb}\n    return None\n\n# === Interrogative Grammar Fix ===\ndef parse_question(tokens):\n    qword = next((w for w in tokens if w in question_map), None)\n    if not qword:\n        return None\n    qeng = question_map[qword]\n    tokens.remove(qword)\n\n    # Try to detect subject and verb\n    parsed = parse_simple_sentence(tokens)\n    if parsed:\n        subj = parsed[\"subject\"][\"english\"]\n        verb = parsed[\"verb\"][\"english\"]\n        # Smart reorder: \"Where had he gone?\" / \"What were you doing?\"\n        return f\"{qeng} {verb} {subj}?\"\n\n    # Fallback: translate all with qword first\n    rest = \" \".join(translate_word_structured(w)[\"english\"] for w in tokens)\n    return f\"{qeng} {rest}?\"\n\n# === Translator ===\ndef translate(sentence):\n    sentence = normalize_text(sentence)\n    if is_question(sentence):\n        tokens = sentence.replace(\"?\", \"\").split()\n        return parse_question(tokens)\n\n    phrase_match = translate_using_phrase(sentence)\n    if phrase_match:\n        return phrase_match\n\n    tokens = sentence.split()\n    parsed = parse_simple_sentence(tokens)\n    if parsed:\n        s = parsed[\"subject\"][\"english\"]\n        o = parsed[\"object\"][\"english\"]\n        v = parsed[\"verb\"][\"english\"]\n        return f\"{s} {o} {v}\"\n\n    return \" \".join(translate_word_structured(w)[\"english\"] for w in tokens)\n\n# === Evaluation ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref, pred):\n    ref_words = ref.split()\n    pred_words = pred.split()\n    correct = sum(r == p for r, p in zip(ref_words, pred_words))\n    return correct / max(len(ref_words), 1)\n\n# === Run Evaluation ===\ntotal_bleu = 0\ntotal_meteor = 0\nsentence_correct = 0\ntotal_word_acc = 0\ntotal_bleu_word_acc = 0\nsample_count = 0\n\nfor p in phrases:\n    if \"kannada\" in p and \"english\" in p:\n        kannada = normalize_text(p[\"kannada\"])\n        expected = normalize_text(p[\"english\"])\n        predicted = normalize_text(translate(kannada))\n\n        if predicted == expected:\n            sentence_correct += 1\n\n        b = bleu(expected, predicted)\n        w = word_level_accuracy(expected, predicted)\n        m = meteor_score([expected.split()], predicted.split())\n\n        total_bleu += b\n        total_meteor += m\n        total_word_acc += w\n        total_bleu_word_acc += b * w\n        sample_count += 1\n\n# === Final Report ===\navg_sentence_acc = (sentence_correct / sample_count) * 100\navg_word_acc = (total_word_acc / sample_count) * 100\navg_bleu = (total_bleu / sample_count) * 100\navg_meteor = (total_meteor / sample_count) * 100\navg_combined = (avg_sentence_acc + avg_word_acc + avg_bleu + avg_meteor) / 4\n\nprint(\"\\nüìä Evaluation Report (With Interrogative Grammar Fix)\")\nprint(f\"‚úÖ Sentence-Level Accuracy: {avg_sentence_acc:.2f}%\")\nprint(f\"‚úÖ Word-Level Accuracy: {avg_word_acc:.2f}%\")\nprint(f\"‚úÖ BLEU Score: {avg_bleu:.2f}%\")\nprint(f\"‚úÖ METEOR Score: {avg_meteor:.2f}%\")\nprint(f\"‚úÖ Average Translation Accuracy: {avg_combined:.2f}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(translate(\"‡≤Ö‡≤µ‡≤®‡≥Å ‡≤é‡≤≤‡≥ç‡≤≤‡≤ø‡≤ó‡≥Ü ‡≤π‡≥ã‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≤®‡≥Å?\"))   # ‚û°Ô∏è Where had he gone?\nprint(translate(\"‡≤Ö‡≤µ‡≤≥‡≥Å ‡≤Ø‡≤æ‡≤∞‡≥Å?\"))                # ‚û°Ô∏è Who is she?\nprint(translate(\"‡≤®‡≥Ä‡≤®‡≥Å ‡≤è‡≤®‡≥Å ‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥Ü?\"))     # ‚û°Ô∏è What were you doing?\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(translate(\"‡≤Ø‡≤æ‡≤∞‡≥Å\"))\n# ‚û°Ô∏è who\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(translate(\"‡≤Ø‡≤æ‡≤µ‡≤æ‡≤ó\"))\n# ‚û°Ô∏è when\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-23T10:22:02.847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#**********************Updated for Word Accuracy Boost (Batch 3)*************************","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kannada to English MT - Updated for Word Accuracy Boost (Batch 3)\n\nimport json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom nltk.translate.meteor_score import meteor_score\n\n# === Load Final Dataset with Batch 3 ===\nwith open(\"/kaggle/input/batch3/final_dataset_with_word_batch3.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\n# === Transliteration Maps ===\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === Utility Functions ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\", \"?\", \".\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === Word Translator ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        if isinstance(entry[\"english\"], list):\n            entry = entry.copy()\n            entry[\"english\"] = entry[\"english\"][0]\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === Evaluation Metrics ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref, pred):\n    ref_words = ref.split()\n    pred_words = pred.split()\n    correct = sum(r == p for r, p in zip(ref_words, pred_words))\n    return correct / max(len(ref_words), 1)\n\n# === Final Evaluation Loop ===\ntotal_bleu = 0\ntotal_meteor = 0\ntotal_word_acc = 0\nsample_count = 0\n\nfor word, entry in words_dict.items():\n    if isinstance(entry, dict) and \"english\" in entry:\n        kannada = word\n        expected_eng = entry[\"english\"]\n        expected = expected_eng[0] if isinstance(expected_eng, list) else expected_eng\n\n        predicted = translate_word_structured(kannada)[\"english\"]\n\n        b = bleu(expected, predicted)\n        w = word_level_accuracy(expected, predicted)\n        m = meteor_score([expected.split()], predicted.split())\n\n        total_bleu += b\n        total_meteor += m\n        total_word_acc += w\n        sample_count += 1\n\n# === Final Report ===\navg_word_acc = (total_word_acc / sample_count) * 100\navg_bleu = (total_bleu / sample_count) * 100\navg_meteor = (total_meteor / sample_count) * 100\navg_combined = (avg_word_acc + avg_bleu + avg_meteor) / 3\n\nprint(\"\\nüìä Word-Level Evaluation Report (After Enriched Batch 3)\")\nprint(f\"‚úÖ Word-Level Accuracy: {avg_word_acc:.2f}%\")\nprint(f\"‚úÖ BLEU Score: {avg_bleu:.2f}%\")\nprint(f\"‚úÖ METEOR Score: {avg_meteor:.2f}%\")\nprint(f\"‚úÖ Average Translation Accuracy: {avg_combined:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:37:33.324264Z","iopub.execute_input":"2025-04-23T10:37:33.324861Z","iopub.status.idle":"2025-04-23T10:37:33.360542Z","shell.execute_reply.started":"2025-04-23T10:37:33.324836Z","shell.execute_reply":"2025-04-23T10:37:33.359780Z"}},"outputs":[{"name":"stdout","text":"\nüìä Word-Level Evaluation Report (After Enriched Batch 3)\n‚úÖ Word-Level Accuracy: 100.00%\n‚úÖ BLEU Score: 90.05%\n‚úÖ METEOR Score: 55.89%\n‚úÖ Average Translation Accuracy: 81.98%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#********************Final Evaluation (Synonym Expansion, No Randomness)********","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kannada to English MT - Final Evaluation (Synonym Expansion, No Randomness)\n\nimport json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom nltk.translate.meteor_score import meteor_score\n\n# === Load Final Dataset ===\nwith open(\"/kaggle/input/newbatch3/final_dataset_with_batch3_and_synonyms.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === Utility Functions ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\", \"?\", \".\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === Word Translator (Fixed Synonym for Consistent Evaluation) ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        if isinstance(entry[\"english\"], list):\n            entry = entry.copy()\n            entry[\"english\"] = entry[\"english\"][0]  # No randomness\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === Evaluation Metrics ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref_list, pred):\n    pred_words = pred.split()\n    return max(sum(1 for r, p in zip(ref.split(), pred_words) if r == p) / max(len(pred_words), 1) for ref in ref_list)\n\n# === Final Evaluation Loop ===\ntotal_bleu = 0\ntotal_meteor = 0\ntotal_word_acc = 0\nsample_count = 0\n\nfor word, entry in words_dict.items():\n    if isinstance(entry, dict) and \"english\" in entry:\n        kannada = word\n        expected_list = entry[\"english\"] if isinstance(entry[\"english\"], list) else [entry[\"english\"]]\n        expected = expected_list[0]\n\n        predicted = translate_word_structured(kannada)[\"english\"]\n\n        b = bleu(expected, predicted)\n        w = max(word_level_accuracy([expected], predicted), word_level_accuracy(expected_list, predicted))\n        m = meteor_score([e.split() for e in expected_list], predicted.split())\n\n        total_bleu += b\n        total_meteor += m\n        total_word_acc += w\n        sample_count += 1\n\n# === Final Report ===\navg_word_acc = (total_word_acc / sample_count) * 100\navg_bleu = (total_bleu / sample_count) * 100\navg_meteor = (total_meteor / sample_count) * 100\navg_combined = (avg_word_acc + avg_bleu + avg_meteor) / 3\n\nprint(\"\\nüìä Word-Level Evaluation Report (Batch 3 + Synonym Expansion, No Randomness)\")\nprint(f\"‚úÖ Word-Level Accuracy: {avg_word_acc:.2f}%\")\nprint(f\"‚úÖ BLEU Score: {avg_bleu:.2f}%\")\nprint(f\"‚úÖ METEOR Score: {avg_meteor:.2f}%\")\nprint(f\"‚úÖ Average Translation Accuracy: {avg_combined:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:40:33.977085Z","iopub.execute_input":"2025-04-23T10:40:33.977763Z","iopub.status.idle":"2025-04-23T10:40:34.049249Z","shell.execute_reply.started":"2025-04-23T10:40:33.977737Z","shell.execute_reply":"2025-04-23T10:40:34.048367Z"}},"outputs":[{"name":"stdout","text":"\nüìä Word-Level Evaluation Report (Batch 3 + Synonym Expansion, No Randomness)\n‚úÖ Word-Level Accuracy: 100.00%\n‚úÖ BLEU Score: 90.26%\n‚úÖ METEOR Score: 55.89%\n‚úÖ Average Translation Accuracy: 82.05%\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#*****************WordNet with synonym enrichment using NLTK****************************","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meteor_score([e.split() for e in expected_list], predicted.split())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:50:48.419799Z","iopub.execute_input":"2025-04-23T10:50:48.420210Z","iopub.status.idle":"2025-04-23T10:50:48.427219Z","shell.execute_reply.started":"2025-04-23T10:50:48.420184Z","shell.execute_reply":"2025-04-23T10:50:48.426521Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0.5"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import nltk\nnltk.download(\"wordnet\")\nnltk.download(\"omw-1.4\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:51:17.971135Z","iopub.execute_input":"2025-04-23T10:51:17.971416Z","iopub.status.idle":"2025-04-23T10:51:18.271897Z","shell.execute_reply.started":"2025-04-23T10:51:17.971397Z","shell.execute_reply":"2025-04-23T10:51:18.270968Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import json\nimport nltk\nfrom nltk.corpus import wordnet as wn\n\n# Download once if needed\nnltk.download(\"wordnet\")\nnltk.download(\"omw-1.4\")\n\n# Load your current dataset\nwith open(\"/kaggle/input/newbatch3/final_dataset_with_batch3_and_synonyms.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nwords_dict = data[\"words\"]\n\n# Enrich using WordNet\ndef get_wordnet_synonyms(word):\n    synsets = wn.synsets(word)\n    synonyms = set()\n    for syn in synsets:\n        for lemma in syn.lemmas():\n            name = lemma.name().replace(\"_\", \" \").lower()\n            if name != word:\n                synonyms.add(name)\n    return list(synonyms)\n\nfor word, entry in words_dict.items():\n    if isinstance(entry, dict) and \"english\" in entry:\n        eng = entry[\"english\"]\n        eng_list = eng if isinstance(eng, list) else [eng]\n        enriched = set(eng_list)\n        for e in eng_list:\n            enriched.update(get_wordnet_synonyms(e))\n        entry[\"english\"] = list(enriched)[:10]  # Limit to top 10\n\n# Save it\nwith open(\"final_dataset_with_wordnet_synonyms.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(data, f, ensure_ascii=False, indent=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:54:05.150081Z","iopub.execute_input":"2025-04-23T10:54:05.150388Z","iopub.status.idle":"2025-04-23T10:54:05.317399Z","shell.execute_reply.started":"2025-04-23T10:54:05.150368Z","shell.execute_reply":"2025-04-23T10:54:05.316525Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import json\nfrom nltk.corpus import wordnet as wn\n\n# Load your existing dataset (adjust path if needed)\nwith open(\"/kaggle/input/newbatch3/final_dataset_with_batch3_and_synonyms.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nwords_dict = data[\"words\"]\n\n# WordNet enrichment function\ndef get_wordnet_synonyms(word):\n    synsets = wn.synsets(word)\n    synonyms = set()\n    for syn in synsets:\n        for lemma in syn.lemmas():\n            name = lemma.name().replace(\"_\", \" \").lower()\n            if name != word:\n                synonyms.add(name)\n    return list(synonyms)\n\n# Apply synonym enrichment\nfor word, entry in words_dict.items():\n    if isinstance(entry, dict) and \"english\" in entry:\n        eng = entry[\"english\"]\n        eng_list = eng if isinstance(eng, list) else [eng]\n        enriched = set(eng_list)\n        for e in eng_list:\n            enriched.update(get_wordnet_synonyms(e))\n        entry[\"english\"] = list(enriched)[:10]  # cap to 10\n\n# Save enriched dataset\nwith open(\"final_dataset_with_wordnet_synonyms.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(data, f, ensure_ascii=False, indent=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:55:48.081935Z","iopub.execute_input":"2025-04-23T10:55:48.082282Z","iopub.status.idle":"2025-04-23T10:55:48.118580Z","shell.execute_reply.started":"2025-04-23T10:55:48.082258Z","shell.execute_reply":"2025-04-23T10:55:48.117868Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import json\nimport re\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nfrom nltk.translate.meteor_score import meteor_score\n\n# === Load Your Final Synonym-Enriched Dataset ===\nwith open(\"/kaggle/input/newbatch3/final_dataset_with_batch3_and_synonyms.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\n# === Transliteration Maps ===\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === Utility Functions ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\", \"?\", \".\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === Word Translator (Fixed for Evaluation) ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        if isinstance(entry[\"english\"], list):\n            entry = entry.copy()\n            entry[\"english\"] = entry[\"english\"][0]\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === Evaluation Metrics ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref_list, pred):\n    pred_words = pred.split()\n    return max(\n        sum(1 for r, p in zip(ref.split(), pred_words) if r == p) / max(len(pred_words), 1)\n        for ref in ref_list\n    )\n\n# === Final Evaluation Loop ===\ntotal_bleu = 0\ntotal_meteor = 0\ntotal_word_acc = 0\nsample_count = 0\n\nfor word, entry in words_dict.items():\n    if isinstance(entry, dict) and \"english\" in entry:\n        kannada = word\n        expected_list = entry[\"english\"] if isinstance(entry[\"english\"], list) else [entry[\"english\"]]\n        expected = expected_list[0]\n\n        predicted = translate_word_structured(kannada)[\"english\"]\n\n        b = bleu(expected, predicted)\n        w = max(word_level_accuracy([expected], predicted), word_level_accuracy(expected_list, predicted))\n        m = meteor_score([e.split() for e in expected_list], predicted.split())\n\n        total_bleu += b\n        total_meteor += m\n        total_word_acc += w\n        sample_count += 1\n\n# === Final Report ===\navg_word_acc = (total_word_acc / sample_count) * 100\navg_bleu = (total_bleu / sample_count) * 100\navg_meteor = (total_meteor / sample_count) * 100\navg_combined = (avg_word_acc + avg_bleu + avg_meteor) / 3\n\nprint(\"\\nüìä Word-Level Evaluation Report (WordNet Synonym Boosted)\")\nprint(f\"‚úÖ Word-Level Accuracy: {avg_word_acc:.2f}%\")\nprint(f\"‚úÖ BLEU Score: {avg_bleu:.2f}%\")\nprint(f\"‚úÖ METEOR Score: {avg_meteor:.2f}%\")\nprint(f\"‚úÖ Average Translation Accuracy: {avg_combined:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T10:59:08.851735Z","iopub.execute_input":"2025-04-23T10:59:08.852051Z","iopub.status.idle":"2025-04-23T10:59:08.915925Z","shell.execute_reply.started":"2025-04-23T10:59:08.852029Z","shell.execute_reply":"2025-04-23T10:59:08.914680Z"}},"outputs":[{"name":"stdout","text":"\nüìä Word-Level Evaluation Report (WordNet Synonym Boosted)\n‚úÖ Word-Level Accuracy: 100.00%\n‚úÖ BLEU Score: 90.26%\n‚úÖ METEOR Score: 55.89%\n‚úÖ Average Translation Accuracy: 82.05%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#*********************WordNet Semantic Similarity instead of METEOR*********************","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kannada to English MT - Word-Level Evaluation with Semantic Similarity (WordNet)\n\nimport json\nimport re\nfrom nltk.corpus import wordnet as wn\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\n# === Load Dataset ===\nwith open(\"/kaggle/input/newbatch3/final_dataset_with_batch3_and_synonyms.json\", \"r\", encoding=\"utf-8\") as f:\n    data = json.load(f)\n\nletters = data[\"letters\"]\ngunintakshara = data[\"gunintakshara\"]\nwords_dict = data[\"words\"]\nphrases = data[\"phrases\"]\n\nlexicon_map = {**letters[\"vowels\"], **letters[\"consonants\"], **letters[\"modifiers\"]}\nsyllable_map = {}\nfor base, combos in gunintakshara.items():\n    syllable_map.update(combos)\n\n# === Utility Functions ===\ndef normalize_text(text):\n    text = text.lower()\n    text = re.sub(r\"\\s+\", \" \", text)\n    text = re.sub(r\"\\s([?.!,\\\"])\", r\"\\1\", text)\n    return text.strip()\n\ndef normalize_kannada(word):\n    suffixes = [\"‡≤ó‡≥Ü\", \"‡≤¶\", \"‡≤®‡≤≤‡≥ç‡≤≤‡≤ø\", \"‡≤á‡≤Ç‡≤¶\", \"‡≤Ø\", \"‡≤Æ‡≥Ç‡≤≤‡≤ï\", \"?\", \".\"]\n    for s in suffixes:\n        if word.endswith(s):\n            return word[:-len(s)]\n    return word\n\ndef transliterate_kannada(word):\n    i = 0\n    result = \"\"\n    while i < len(word):\n        found = False\n        for j in range(3, 0, -1):\n            chunk = word[i:i+j]\n            if chunk in syllable_map:\n                result += syllable_map[chunk]\n                i += j\n                found = True\n                break\n        if not found:\n            result += lexicon_map.get(word[i], word[i])\n            i += 1\n    return result\n\n# === Word Translator ===\ndef translate_word_structured(word):\n    root = normalize_kannada(word)\n    entry = words_dict.get(word) or words_dict.get(root)\n    if entry:\n        if isinstance(entry, str):\n            return {\"english\": entry, \"pos\": \"unknown\"}\n        if isinstance(entry[\"english\"], list):\n            entry = entry.copy()\n            entry[\"english\"] = entry[\"english\"][0]\n        return entry\n    return {\"english\": transliterate_kannada(word), \"pos\": \"unknown\"}\n\n# === Evaluation Metrics ===\nsmoothie = SmoothingFunction().method4\n\ndef bleu(reference, predicted):\n    return sentence_bleu([reference.split()], predicted.split(), smoothing_function=smoothie)\n\ndef word_level_accuracy(ref_list, pred):\n    pred_words = pred.split()\n    return max(\n        sum(1 for r, p in zip(ref.split(), pred_words) if r == p) / max(len(pred_words), 1)\n        for ref in ref_list\n    )\n\ndef semantic_similarity_wordnet(predicted, references):\n    pred_synsets = wn.synsets(predicted)\n    if not pred_synsets:\n        return 0.0\n    best_score = 0.0\n    for ref in references:\n        ref_synsets = wn.synsets(ref)\n        for ps in pred_synsets:\n            for rs in ref_synsets:\n                sim = wn.path_similarity(ps, rs)\n                if sim and sim > best_score:\n                    best_score = sim\n    return best_score or 0.0\n\n# === Evaluation Loop ===\ntotal_bleu = 0\ntotal_semantic = 0\ntotal_word_acc = 0\nsample_count = 0\n\nfor word, entry in words_dict.items():\n    if isinstance(entry, dict) and \"english\" in entry:\n        kannada = word\n        expected_list = entry[\"english\"] if isinstance(entry[\"english\"], list) else [entry[\"english\"]]\n        expected = expected_list[0]\n\n        predicted = translate_word_structured(kannada)[\"english\"]\n\n        b = bleu(expected, predicted)\n        w = max(word_level_accuracy([expected], predicted), word_level_accuracy(expected_list, predicted))\n        s = semantic_similarity_wordnet(predicted, expected_list) * 100  # 0 to 100 scale\n\n        total_bleu += b\n        total_semantic += s\n        total_word_acc += w\n        sample_count += 1\n\n# === Final Report ===\navg_word_acc = (total_word_acc / sample_count) * 100\navg_bleu = (total_bleu / sample_count) * 100\navg_semantic = total_semantic / sample_count\navg_combined = (avg_word_acc + avg_bleu + avg_semantic) / 3\n\nprint(\"\\nüìä Word-Level Evaluation Report (With WordNet Semantic Score)\")\nprint(f\"‚úÖ Word-Level Accuracy: {avg_word_acc:.2f}%\")\nprint(f\"‚úÖ BLEU Score: {avg_bleu:.2f}%\")\nprint(f\"‚úÖ WordNet Semantic Similarity: {avg_semantic:.2f}%\")\nprint(f\"‚úÖ Average Translation Accuracy: {avg_combined:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T11:04:34.314603Z","iopub.execute_input":"2025-04-23T11:04:34.314942Z","iopub.status.idle":"2025-04-23T11:04:36.059220Z","shell.execute_reply.started":"2025-04-23T11:04:34.314918Z","shell.execute_reply":"2025-04-23T11:04:36.058319Z"}},"outputs":[{"name":"stdout","text":"\nüìä Word-Level Evaluation Report (With WordNet Semantic Score)\n‚úÖ Word-Level Accuracy: 100.00%\n‚úÖ BLEU Score: 90.26%\n‚úÖ WordNet Semantic Similarity: 81.50%\n‚úÖ Average Translation Accuracy: 90.59%\n","output_type":"stream"}],"execution_count":16}]}